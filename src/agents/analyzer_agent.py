"""
Agente Analizador Cl√≠nico - Especializado en la interpretaci√≥n y generaci√≥n de informes.
"""

import json
from typing import Dict, Any
from .base_agent import BaseLLMAgent, BaseAgentConfig

ANALYZER_SYSTEM_PROMPT = """
Eres un Cient√≠fico de Datos especializado en salud. Tu tarea es recibir un an√°lisis t√©cnico de un dataset (en JSON) y redactar un informe de an√°lisis exploratorio (EDA) en Markdown.

**ENTRADA (JSON):**
Recibir√°s un JSON con la estructura:

```json
{{
  "dataset_type": "<tipo>",
  "column_mapping": {{"age_col": "<col>", ...}},
  "basic_stats": {{"rows": <num>, ...}},
  "missing_values": {{"total_missing": <num>, ...}},
  "column_analysis": {{"<col_1>": {{"type": "...", ...}}}}
}}
```

**TAREA (MARKDOWN):**
Tu √öNICA salida debe ser un informe en MARKDOWN con estas secciones:

1.  **`### üìù Resumen Ejecutivo`**: P√°rrafo con los hallazgos clave.
2.  **`### üìä An√°lisis Descriptivo`**: Caracter√≠sticas del dataset.
3.  **`### ü©∫ Calidad de los Datos`**: Evaluaci√≥n de nulos y duplicados.
4.  **`### üî¨ An√°lisis de Variables Clave`**: Descripci√≥n de las variables m√°s importantes (edad, g√©nero, diagn√≥stico).
5.  **`### üí° Conclusiones y Recomendaciones`**: Idoneidad del dataset para IA y posibles sesgos.

Basa todas tus afirmaciones en los datos del JSON. S√© profesional y objetivo.
"""

class ClinicalAnalyzerConfig(BaseAgentConfig):
    name: str = "Analizador Cl√≠nico"
    description: str = "Especialista en an√°lisis estad√≠stico y exploratorio de datos m√©dicos."
    system_prompt: str = ANALYZER_SYSTEM_PROMPT
    max_tokens: int = 2500

class ClinicalAnalyzerAgent(BaseLLMAgent):
    def __init__(self):
        super().__init__(ClinicalAnalyzerConfig(), tools=[])  # Expl√≠citamente sin herramientas

    async def process(self, input_text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        # El an√°lisis se dispara por `analyze_dataset`, no por `process`.
        if context and context.get("universal_analysis"):
            return await self.analyze_dataset(None, context)
        return {"message": "El analizador necesita un an√°lisis universal previo.", "agent": self.name, "error": True}

    async def analyze_dataset(self, dataframe, context: Dict[str, Any] = None) -> Dict[str, Any]:
        universal_analysis_result = context.get("universal_analysis")
        if not universal_analysis_result:
            return {"message": "Error: No se encontr√≥ el resultado del an√°lisis universal.", "agent": self.name, "error": True}

        prompt_input = json.dumps(universal_analysis_result, indent=2)
        
        # Construir el diccionario de entrada para el prompt
        prompt_variables = {
            "input": prompt_input,
        }
        
        # Agregar chat_history si hay mensajes en memoria
        if self.memory.chat_memory.messages:
            prompt_variables["chat_history"] = self.memory.chat_memory.messages
        
        llm_response = await self.agent_executor.ainvoke(prompt_variables)
        
        # Manejar diferentes tipos de respuesta del LLM
        if hasattr(llm_response, 'content'):
            response_text = llm_response.content
        elif isinstance(llm_response, str):
            response_text = llm_response
        else:
            response_text = str(llm_response)
        
        return {
            "message": response_text,
            "agent": self.name,
            "analysis_complete": True
        }