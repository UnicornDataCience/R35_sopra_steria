import os
import asyncio
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# Cargar variables de entorno
load_dotenv()

async def test_azure_openai_basic():
    """Test bÃ¡sico de conexiÃ³n con Azure OpenAI"""
    
    print("ğŸ§ª **PRUEBA BÃSICA DE AZURE OPENAI**")
    print("=" * 50)
    
    # 1. Verificar variables de entorno
    print("\nğŸ”§ **CONFIGURACIÃ“N:**")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4-TFM")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
    
    print(f"Endpoint: {endpoint}")
    print(f"Deployment: {deployment}")
    print(f"API Version: {api_version}")
    print(f"API Key: {'âœ… Configurada' if api_key else 'âŒ No encontrada'}")
    
    if not all([endpoint, api_key, deployment]):
        print("\nâŒ **ERROR:** ConfiguraciÃ³n incompleta")
        print("Verifica tu archivo .env")
        return False
    
    try:
        print("\nğŸš€ **CONECTANDO...**")
        
        # Crear cliente Azure OpenAI
        llm = AzureChatOpenAI(
            azure_deployment=deployment,
            azure_endpoint=endpoint,
            api_key=api_key,
            api_version=api_version,
            temperature=0.1,
            max_tokens=1000
        )
        
        print("âœ… Cliente creado exitosamente")
        
        # Test 1: Mensaje simple
        print("\nğŸ”„ **TEST 1:** Mensaje simple...")
        response = await llm.ainvoke("Di 'Hola' en una frase simple")
        print(f"âœ… Respuesta: {response.content}")
        
        # Test 2: ConversaciÃ³n mÃ©dica bÃ¡sica
        print("\nğŸ”„ **TEST 2:** Contexto mÃ©dico...")
        messages = [
            SystemMessage(content="Eres un asistente mÃ©dico especializado en datos sintÃ©ticos."),
            HumanMessage(content="Â¿QuÃ© son los datos sintÃ©ticos en medicina?")
        ]
        response = await llm.ainvoke(messages)
        print(f"âœ… Respuesta: {response.content[:200]}...")
        
        # Test 3: GeneraciÃ³n de datos mock
        print("\nğŸ”„ **TEST 3:** GeneraciÃ³n de ejemplo...")
        mock_prompt = """Genera un ejemplo de paciente COVID-19 sintÃ©tico con estos campos:
        - ID del paciente
        - Edad
        - Sexo
        - DiagnÃ³stico
        - Medicamento
        - DÃ­as en UCI
        - Temperatura de ingreso
        - SaturaciÃ³n O2
        - Resultado
        - Motivo de alta
        
        Responde solo con el ejemplo, sin explicaciones."""
        
        response = await llm.ainvoke(mock_prompt)
        print(f"âœ… Ejemplo generado:\n{response.content}")
        
        print("\nğŸ‰ **TODAS LAS PRUEBAS EXITOSAS**")
        print("La conexiÃ³n con Azure OpenAI estÃ¡ funcionando correctamente")
        return True
        
    except Exception as e:
        print(f"\nâŒ **ERROR EN CONEXIÃ“N:** {e}")
        print("\nğŸ” **POSIBLES CAUSAS:**")
        print("â€¢ API key incorrecta o expirada")
        print("â€¢ Endpoint incorrecto")
        print("â€¢ Deployment no disponible")
        print("â€¢ Problemas de red/firewall")
        return False

if __name__ == "__main__":
    result = asyncio.run(test_azure_openai_basic())
    if result:
        print("\nâœ… Tu configuraciÃ³n Azure OpenAI estÃ¡ lista para usar!")
    else:
        print("\nâŒ Revisa tu configuraciÃ³n antes de continuar")