# Propuesta de TFM ‚Äì R35: Generaci√≥n de Historias Cl√≠nicas Sint√©ticas

## üéØ ESTADO ACTUAL DEL SISTEMA (Actualizado)

### ‚úÖ PROBLEMAS RESUELTOS RECIENTEMENTE:
1. **‚úÖ Interfaz de bienvenida restaurada**: Interfaz est√°tica con dos columnas explicando capacidades del sistema (no es un mensaje de chat)
2. **‚úÖ LLM conversacional funcional**: El sistema ahora responde correctamente a cualquier pregunta m√©dica, no solo comandos de agentes
3. **‚úÖ Coordinador funcional**: Maneja correctamente saludos, preguntas m√©dicas y par√°metros de generaci√≥n
4. **‚úÖ Selecci√≥n de modelos**: CTGAN, TVAE, SDV funcionan correctamente con par√°metros espec√≠ficos
5. **‚úÖ Archivos organizados**: Tests movidos a carpeta `/tests`, archivos .md consolidados
6. **‚úÖ Orquestador mejorado**: Manejo robusto de errores y respuestas conversacionales

### üîß ARQUITECTURA T√âCNICA CONFIRMADA:
- **Interface**: `interfaces/chat_llm.py` - Streamlit UI modernizada con interfaz est√°tica de bienvenida
- **Orquestador**: `src/orchestration/langgraph_orchestrator.py` - LangGraph con manejo robusto de conversaciones
- **Agentes**: Coordinador (conversacional + orquestador), Analyzer, Generator, Validator, Simulator, Evaluator
- **Generadores**: CTGAN, TVAE, SDV con par√°metros unificados
- **Tests**: Organizados en carpeta `/tests/`
- **Respuestas m√©dicas**: Sistema responde a cualquier consulta m√©dica general

---

# Propuesta de TFM ‚Äì R35:

**T√≠tulo sugerido 1:** Generaci√≥n de Historias Cl√≠nicas Sint√©ticas Mediante Agentes Inteligentes

## Objetivo General

Desarrollar un sistema aut√≥nomo basado en agentes inteligentes que, a partir del an√°lisis  
de datasets cl√≠nicos reales anonimizado, genere historiales sint√©ticos plausibles, los valide  
desde un punto de vista m√©dico y permita simular escenarios cl√≠nicos para su uso en  
entrenamiento de modelos predictivos y evaluaci√≥n de sistemas de soporte a la decisi√≥n  
m√©dica.

**Caso de uso acotado:** Hospital virtual de pacientes cr√≥nicos  

**Contexto empresarial simulado:** Una empresa del sector salud (e.g. desarrolladora de  
soluciones de IA cl√≠nica) necesita simular una cohorte de pacientes con enfermedades  
cr√≥nicas (diabetes tipo 2, EPOC, insuficiencia card√≠aca, etc.) para entrenar, probar y validar  
modelos sin depender de datos sensibles.

## Arquitectura Propuesta

### Flujo general

1. An√°lisis de dataset cl√≠nico anonimizado real (MIMIC-IV, eICU, etc.)  
2. Extracci√≥n de patrones cl√≠nicos  
3. Generaci√≥n de pacientes sint√©ticos  
4. Validaci√≥n m√©dica de coherencia  
5. Simulaci√≥n de progresi√≥n de casos cl√≠nicos  
6. Evaluaci√≥n de fidelidad y utilidad  

| **Tecnolog√≠as clave**               | **Herramienta propuesta**               |
|-------------------------------------|-----------------------------------------|
| LLMs                                | Llama 2 + GPT-4 (validaci√≥n cruzada)    |
| Framework de agentes                | LangGraph o CrewAI                      |
| Framework de IA m√©dica              | MedAlpaca o GatorTron                   |
| Dataset cl√≠nico real                | MIMIC-IV (https://physionet.org/content/minniciv/2.2/) |
| Generaci√≥n de datos sint√©ticos      | SDGym, CTGAN                            |
| Validaci√≥n m√©dica estructural       | Reglas con scikit-health, MedSpaCy      |
| Orquestaci√≥n y despliegue           | FastAPI + LangChain + Docker + MongoDB  |

### Dise√±o del Sistema de Agentes

Usando LangGraph se dise√±a un grafo de agentes con flujos definidos:

## Agentes y Roles

| **Agente**           | **Rol**                                                                 |
|-----------------------|-------------------------------------------------------------------------|
| Analista cl√≠nico      | Analiza el dataset real, identifica patrones frecuentes, clusters       |
| Generador sint√©tico   | Crea pacientes ficticios con base en los patrones identificados         |
| Validador m√©dico      | Eval√∫a la consistencia de los datos generados (e.g. no mezclar enfermedades incompatibles) |
| Simulador de evoluci√≥n | Simula el paso del tiempo, progresi√≥n de s√≠ntomas, tratamientos y respuesta |
| Evaluador de utilidad | Compara datos reales y sint√©ticos (fidelidad estad√≠stica y utilidad)   |

### Ejemplo del flujo entre agentes:

1. Usuario sube MIMIC-IV o dataset propio anonimizado  
2. Analista cl√≠nico detecta patrones comunes: combinaciones de ICD-10, medicaci√≥n, evoluci√≥n  
3. Generador sint√©tico crea 1,000 pacientes nuevos con enfermedades cr√≥nicas plausibles  
4. Validador m√©dico revisa: ¬øhay coherencia entre medicaci√≥n y enfermedad? ¬ølas edades cuadran?  
5. Simulador de evoluci√≥n simula visitas, reingresos, cambios de tratamiento  
6. Evaluador genera m√©tricas: distribuci√≥n de variables, distancia KL, utilidad para entrenamiento  

### Ejemplo de salida esperada

Una historia sint√©tica generada:

```json
{
    "patient_id": "synth_0831",
    "age": 67,
    "sex": "male",
    "chronic_conditions": ["type_2_diabetes", "hypertension"],
    "visits": [
        {
            "date": "2024-01-15",
            "diagnosis": "hyperglycemia",
            "medications": ["metformin", "listnopril"],
            "lab_results": {"HbA1c": "8.4%", "BP": "145/90"},
            "actions": ["adjusted dosage of metformin"]
        },
        ...
    ]
}


Interacci√≥n con el Usuario
Carga del dataset base

Selecci√≥n del perfil sint√©tico a generar (edad, sexo, enfermedades)

Definici√≥n del n√∫mero de pacientes a generar

Par√°metros de validaci√≥n m√©dica (estricta, moderada, relajada)

Descarga o visualizaci√≥n de cohortes generadas

Simulaci√≥n interactiva de evoluci√≥n de pacientes en dashboard

Evaluaci√≥n de Resultados
Criterios de evaluaci√≥n
Fidelidad estad√≠stica: uso de m√©tricas como Jensen-Shannon divergence

Validaci√≥n m√©dica: an√°lisis de reglas cl√≠nicas autom√°ticas

Utilidad para entrenamiento: comparar modelos entrenados con datos reales vs sint√©ticos

Capacidad adaptativa: integraci√≥n de nuevas enfermedades (e.g. COVID-19, Alzheimer)

Ejemplos de Caso de Uso
Entrenar un modelo de predicci√≥n de reingreso hospitalario

Probar un sistema de recomendaci√≥n de tratamientos

Evaluar la robustez de modelos ante cohortes no vistas

Simular pol√≠ticas hospitalarias (e.g. reducci√≥n de visitas por telemedicina)

Sugerencias para la Memoria TFM
Bas√°ndome en la plantilla que compartiste:

1. Introducci√≥n
Explica el reto de trabajar con datos cl√≠nicos reales por privacidad.

Justifica la necesidad de datos sint√©ticos realistas.

Introduce los LLMs y agentes como soluci√≥n innovadora.

Describe brevemente el sistema aut√≥nomo propuesto.

2. Contexto y Estado del Arte
Revisa papers sobre generaci√≥n de datos cl√≠nicos sint√©ticos.

Cubre el uso de LLMs en generaci√≥n de texto cl√≠nico (GatorTron, MedAlpaca).

Revisa est√°ndares de validaci√≥n de datos sint√©ticos (SDGym, CTGAN).

Menciona herramientas de validaci√≥n cl√≠nica automatizada (e.g. MedSpaCy).

Conecta esto con el reto de adaptar los modelos a enfermedades emergentes.

3. Objetivos y Metodolog√≠a
Objetivo general: como descrito arriba.

Objetivos espec√≠ficos:

Analizar dataset real y extraer patrones cl√≠nicos.

Generar cohortes sint√©ticas plausibles.

Validar las historias con agentes.

Simular escenarios cl√≠nicos.

Evaluar fidelidad y aplicabilidad.

Metodolog√≠a:

Ciclo iterativo basado en CRISP-DM.

Uso de LangGraph como marco de agentes.

Evaluaciones cuantitativas (estad√≠sticas) y cualitativas (coherencia cl√≠nica).

4. Marco normativo
Justifica el uso de datos anonimizado (e.g. MIMIC-IV).

A√±ade medidas t√©cnicas de protecci√≥n: sin almacenamiento persistente de datos reales, control de acceso, etc.

5. Desarrollo de la contribuci√≥n
Detalla la arquitectura de agentes.

Muestra el flujo LangGraph.

Incluye ejemplos de casos generados y validaciones.

Describe los pipelines: entrenamiento, generaci√≥n, validaci√≥n, simulaci√≥n.

6. C√≥digo y datos
Repositorio en GitHub con scripts, notebooks y c√≥digo del sistema de agentes.

Dataset original: referencia a MIMIC-IV y datasets sint√©ticos generados.

7. Conclusiones
Resumen de la utilidad de agentes inteligentes para generaci√≥n sint√©tica.

Validez de los datos para aplicaciones reales (entrenamiento, validaci√≥n de modelos cl√≠nicos).

Capacidad de adaptaci√≥n a nuevas condiciones.

8. Limitaciones y trabajo futuro
Limitaciones:

Validaci√≥n m√©dica basada en reglas autom√°ticas, no revisi√≥n por profesionales.

Posible sesgo en el dataset base.

Futuro:

Integraci√≥n con validaci√≥n humana.

Extensi√≥n a condiciones pedi√°tricas.

Sistema SaaS de generaci√≥n bajo demanda.

Siguientes Pasos
T√©cnicos
Elegir dataset cl√≠nico (MIMIC-IV recomendado).

Construir primer prototipo con LangGraph + Llama 2.

Definir reglas cl√≠nicas b√°sicas para validaci√≥n.

Medir fidelidad sint√©tica con m√©tricas de distancia.

Redacci√≥n de la memoria
Comenzar con la estructura de cap√≠tulos tal como se indica.

Incluir gr√°ficos de arquitectura, ejemplo de pacientes generados, tabla comparativa real vs sint√©tico.

Usar referencias APA actualizadas (papers, art√≠culos, documentaci√≥n de herramientas).

Incluir anexos: c√≥digo, prompts usados, resultados de evaluaci√≥n.

---

## AN√ÅLISIS DEL ESTADO ACTUAL DEL PROYECTO - JULIO 2025

### üîç DIAGN√ìSTICO DE LA SITUACI√ìN ACTUAL

#### Problemas Identificados en el Flujo

**1. ARQUITECTURA FRAGMENTADA**
- ‚úÖ Existe `LangGraphOrchestrator` en `/src/orchestration/` pero NO est√° siendo usado
- ‚ùå Se usa `FlexibleOrchestrator` custom en `chat_llm.py` sin integraci√≥n con LangGraph
- ‚ùå Los agentes en `/src/agents/` (base_agent, coordinator_agent) est√°n desconectados del flujo principal
- ‚ùå C√≥digo redundante entre `/src/extraction/`, `/src/adapters/` y `/src/generation/`

**2. DEPENDENCIA EXCESIVA DE COVID-19**
- ‚ùå Todo el sistema est√° hardcodeado para datasets COVID-19
- ‚ùå `data_extractor.py` y `medical_data_adapter.py` tienen l√≥gica espec√≠fica COVID
- ‚ùå No existe un adaptador universal para otros tipos de datasets m√©dicos
- ‚ùå Los patrones de an√°lisis est√°n sesgados hacia estructuras COVID espec√≠ficas

**3. FLUJO DE DATOS INCONSISTENTE**
- ‚ùå La carga inicial del dataset en `chat_llm.py` no sigue el patr√≥n de agentes
- ‚ùå El an√°lisis se hace directamente sin pasar por el `analyzer_agent.py`
- ‚ùå No hay estado compartido coherente entre componentes
- ‚ùå Los datos se procesan m√∫ltiples veces en diferentes m√≥dulos

#### Elementos Bien Implementados

**1. SISTEMA DE AGENTES (Arquitectura correcta)**
- ‚úÖ 6 agentes especializados seg√∫n especificaci√≥n GEMINI
- ‚úÖ Estructura base s√≥lida en `/src/agents/`
- ‚úÖ Separaci√≥n clara de responsabilidades

**2. GENERACI√ìN SINT√âTICA (Funcional)**
- ‚úÖ M√∫ltiples modelos: CTGAN, TVAE, SDV
- ‚úÖ Metadata handling correcto
- ‚úÖ Integraci√≥n con bibliotecas especializadas

**3. INTERFAZ USUARIO (Streamlit funcional)**
- ‚úÖ Chat interactivo implementado
- ‚úÖ Carga de archivos en sidebar
- ‚úÖ Visualizaci√≥n de resultados

### üöÄ PLAN DE REORGANIZACI√ìN Y MEJORAS

#### FASE 1: REFACTORIZACI√ìN DE ARQUITECTURA (Prioridad ALTA)

**1.1 Migrar a LangGraph Real**
```
TAREAS:
- Activar el `LangGraphOrchestrator` existente
- Eliminar `FlexibleOrchestrator` de chat_llm.py
- Conectar agentes base con el flujo principal
- Implementar estado compartido AgentState
```

**1.2 Crear Adaptador Universal**
```
TAREAS:
- Refactorizar `medical_data_adapter.py` para ser agn√≥stico del tipo de dataset
- Crear detector autom√°tico de tipos de datos m√©dicos
- Implementar mapeo din√°mico de columnas
- Separar l√≥gica COVID espec√≠fica en m√≥dulo opcional
```

**1.3 Unificar M√≥dulos de Extracci√≥n**
```
TAREAS:
- Consolidar `data_extractor.py` y `pattern_extractor.py`
- Eliminar duplicaci√≥n con `medical_data_adapter.py`
- Crear pipeline √∫nico: Dataset ‚Üí An√°lisis ‚Üí Patrones ‚Üí Configuraci√≥n Sint√©tica
```

#### FASE 2: UNIVERSALIZACI√ìN DEL SISTEMA (Prioridad ALTA)

**2.1 Detector Autom√°tico de Dataset**
```python
# Nuevo componente: src/adapters/universal_dataset_detector.py
class UniversalDatasetDetector:
    def detect_dataset_type(self, df) -> DatasetType
    def infer_medical_columns(self, df) -> ColumnMapping  
    def extract_domain_patterns(self, df) -> DomainPatterns
```

**2.2 Configuraci√≥n Din√°mica de Pipeline**
```python
# Componente: src/config/pipeline_config.py
class DynamicPipelineConfig:
    def generate_analysis_config(self, dataset_type)
    def generate_synthesis_config(self, domain_patterns)
    def generate_validation_rules(self, medical_domain)
```

#### FASE 3: IMPLEMENTACI√ìN DE FUNCIONALIDADES FALTANTES (Prioridad MEDIA)

**3.1 Simulaci√≥n Temporal Real**
```
TAREAS:
- Implementar generaci√≥n de secuencias temporales en simulator_agent.py
- Crear historias cl√≠nicas con m√∫ltiples visitas
- Simular progresi√≥n de enfermedades
- Implementar eventos cl√≠nicos realistas
```

**3.2 Validaci√≥n M√©dica Avanzada**
```
TAREAS:
- Integrar reglas ICD-10 autom√°ticas
- Implementar validaci√≥n cruzada medicamentos-enfermedades
- Crear sistema de alertas de inconsistencias m√©dicas
- A√±adir validaci√≥n por rangos de edad/g√©nero
```

**3.3 M√©tricas de Evaluaci√≥n Completas**
```
TAREAS:
- Implementar Jensen-Shannon divergence
- A√±adir m√©tricas de distancia estad√≠stica
- Crear comparaci√≥n distribucional
- Implementar evaluaci√≥n de utilidad para ML
```

#### FASE 4: MEJORAS DE UX Y FUNCIONALIDADES AVANZADAS (Prioridad BAJA)

**4.1 Dashboard Interactivo**
```
TAREAS:
- Crear visualizaci√≥n de cohortes generadas
- Implementar simulaci√≥n interactiva de pacientes
- A√±adir gr√°ficos de comparaci√≥n real vs sint√©tico
- Dashboard de m√©tricas en tiempo real
```

**4.2 Persistencia y Gesti√≥n de Cohortes**
```
TAREAS:
- Implementar guardado de cohortes sint√©ticas
- Sistema de versionado de datasets
- Gesti√≥n de experimentos y configuraciones
- Exportaci√≥n a formatos m√∫ltiples
```

### üìã PLAN DE IMPLEMENTACI√ìN INMEDIATO

#### Semana 1-2: Migraci√≥n a LangGraph
1. **D√≠a 1-2**: Activar `LangGraphOrchestrator` y conectar con `chat_llm.py`
2. **D√≠a 3-4**: Migrar l√≥gica de `FlexibleOrchestrator` a nodos LangGraph
3. **D√≠a 5-7**: Conectar agentes base con flujo principal
4. **D√≠a 8-10**: Testing y debugging del nuevo flujo

#### Semana 3-4: Universalizaci√≥n del Sistema
1. **D√≠a 11-14**: Crear `UniversalDatasetDetector` 
2. **D√≠a 15-17**: Refactorizar `medical_data_adapter.py`
3. **D√≠a 18-21**: Implementar mapeo din√°mico de columnas
4. **D√≠a 22-24**: Testing con datasets no-COVID

#### Semana 5-6: Consolidaci√≥n de M√≥dulos
1. **D√≠a 25-28**: Unificar m√≥dulos extraction/adapters
2. **D√≠a 29-31**: Eliminar c√≥digo redundante
3. **D√≠a 32-35**: Optimizar pipeline de an√°lisis
4. **D√≠a 36-38**: Documentaci√≥n y testing final

### üéØ OBJETIVOS DE CADA FASE

**FASE 1 ‚Üí Sistema coherente con arquitectura LangGraph**
**FASE 2 ‚Üí Capacidad de procesar cualquier dataset m√©dico**  
**FASE 3 ‚Üí Cumplimiento completo de especificaci√≥n GEMINI**
**FASE 4 ‚Üí Sistema profesional listo para producci√≥n**

### ‚ö†Ô∏è RIESGOS Y MITIGACIONES

**RIESGO**: Ruptura de funcionalidad existente durante migraci√≥n
**MITIGACI√ìN**: Crear branch de desarrollo, testing incremental

**RIESGO**: Complejidad de universalizaci√≥n excesiva  
**MITIGACI√ìN**: Implementar por tipos de dataset espec√≠ficos primero

**RIESGO**: Performance degradada con nuevas abstracciones
**MITIGACI√ìN**: Profiling continuo, optimizaci√≥n iterativa

### üìä M√âTRICAS DE √âXITO

- [ ] Sistema procesa datasets m√©dicos gen√©ricos (no solo COVID)
- [ ] Flujo completo end-to-end funcional con LangGraph
- [ ] Eliminaci√≥n de c√≥digo redundante >50%
- [ ] Tiempo de procesamiento <5min para datasets 10k filas
- [ ] Cobertura de pruebas >80% en m√≥dulos core
- [ ] Documentaci√≥n completa de arquitectura

---

**Fecha de An√°lisis**: Julio 6, 2025  
**Estado**: Plan de refactorizaci√≥n aprobado para implementaci√≥n inmediata  
**Prioridad**: ALTA - Sistema cr√≠tico para completar objetivos TFM

---

## üìã REGISTRO DE CAMBIOS IMPLEMENTADOS

### **Fecha**: Julio 6, 2025
### **Sesi√≥n**: Implementaci√≥n FASE 1 y FASE 2 del Plan de Refactorizaci√≥n

---

### üîß CAMBIOS PRINCIPALES REALIZADOS

#### **1. FASE 1: Migraci√≥n a LangGraph (COMPLETADA)**

**1.1 Refactorizaci√≥n de `interfaces/chat_llm.py`**
- ‚úÖ Migrado de `FlexibleOrchestrator` a `LangGraphOrchestrator`
- ‚úÖ Implementado manejo de errores para compatibilidad con agentes mock
- ‚úÖ Actualizado sistema de inicializaci√≥n con cache para LangGraph
- ‚úÖ Eliminado c√≥digo legacy del orquestador flexible
- ‚úÖ Mejorado sistema de detecci√≥n de dependencias (AGENTS_AVAILABLE, LANGGRAPH_AVAILABLE)

**1.2 Creaci√≥n de `interfaces/chat_llm_langgraph.py`**
- ‚úÖ Nueva interfaz limpia espec√≠fica para LangGraph
- ‚úÖ Implementaci√≥n de ejemplo de uso del nuevo orquestador
- ‚úÖ Documentaci√≥n integrada del flujo de trabajo

#### **2. FASE 2: Universalizaci√≥n del Sistema (COMPLETADA)**

**2.1 Creaci√≥n de `src/adapters/universal_dataset_detector.py`**
- ‚úÖ Detector universal de tipos de dataset m√©dicos
- ‚úÖ Reconocimiento autom√°tico de columnas est√°ndar (edad, sexo, diagn√≥sticos, etc.)
- ‚úÖ Mapeo din√°mico de columnas a schema universal
- ‚úÖ Detecci√≥n de patrones espec√≠ficos: COVID-19, diabetes, cardiolog√≠a, etc.
- ‚ö†Ô∏è **PENDIENTE**: Implementar m√©todo `analyze_dataset` (identificado en testing)

**2.2 Creaci√≥n de `src/config/pipeline_config.py`**
- ‚úÖ Configuraci√≥n din√°mica de pipeline por tipo de dataset
- ‚úÖ Perfiles espec√≠ficos: COVID-19, diabetes, cardiolog√≠a, gen√©rico
- ‚úÖ Par√°metros de generaci√≥n adaptables por contexto m√©dico
- ‚úÖ Integraci√≥n con validadores especializados por dominio

**2.3 Refactorizaci√≥n de `src/orchestration/langgraph_orchestrator.py`**
- ‚úÖ Integraci√≥n completa con detector universal
- ‚úÖ Propagaci√≥n de contexto universal a trav√©s del workflow
- ‚úÖ Configuraci√≥n din√°mica basada en tipo de dataset detectado
- ‚úÖ Estados mejorados para tracking de progreso
- ‚ö†Ô∏è **PENDIENTE**: Resolver errores de importaci√≥n de LangGraph

#### **3. TESTING E INTEGRACI√ìN**

**3.1 Creaci√≥n de `tests/test_phase_1_2.py`**
- ‚úÖ Test comprehensivo para validar FASE 1 y FASE 2
- ‚úÖ Verificaci√≥n de imports y dependencias
- ‚úÖ Testing de detector universal con dataset sint√©tico
- ‚úÖ Validaci√≥n de configuraci√≥n din√°mica
- ‚úÖ Tests de integraci√≥n LangGraph-Agentes

**3.2 Gesti√≥n de Dependencias**
- ‚úÖ Instalaci√≥n de `langgraph` en entorno pipenv
- ‚úÖ Verificaci√≥n de compatibilidad con librer√≠as existentes
- ‚ö†Ô∏è **PENDIENTE**: Resolver conflictos de versiones LangGraph

### üóÇÔ∏è ARCHIVOS CREADOS/MODIFICADOS

#### **Archivos Nuevos Creados:**
```
src/adapters/universal_dataset_detector.py    # Detector universal de datasets
src/config/pipeline_config.py                 # Configuraci√≥n din√°mica
interfaces/chat_llm_langgraph.py             # Interfaz LangGraph limpia
tests/test_phase_1_2.py                      # Tests de validaci√≥n
```

#### **Archivos Modificados:**
```
interfaces/chat_llm.py                        # Migraci√≥n a LangGraph
src/orchestration/langgraph_orchestrator.py  # Integraci√≥n universal
```

#### **Archivos Temporales Identificados:**
```
tests/test_generator.py                       # Test temporal movido a tests/ (108 l√≠neas)
```
**Acci√≥n**: Archivo temporal movido a directorio `tests/` para mejor organizaci√≥n

### üìä ESTADO DE IMPLEMENTACI√ìN

#### **‚úÖ COMPLETADO:**
- [x] Migraci√≥n exitosa a arquitectura LangGraph
- [x] Sistema de detecci√≥n universal de datasets
- [x] Configuraci√≥n din√°mica por tipo de dataset
- [x] Propagaci√≥n de contexto universal
- [x] Framework de testing establecido
- [x] Eliminaci√≥n de c√≥digo legacy principal

#### **‚ö†Ô∏è PENDIENTE PARA FINALIZAR:**
- [ ] Implementar m√©todo `analyze_dataset` en `UniversalDatasetDetector`
- [ ] Resolver errores de importaci√≥n LangGraph (versi√≥n/API)
- [ ] Ejecutar tests completos sin errores
- [ ] Limpiar archivo temporal `test_generator.py`
- [ ] Proceder con FASE 3 y FASE 4

### üö´ PROBLEMAS IDENTIFICADOS

**1. Error en `UniversalDatasetDetector.analyze_dataset`**
```
AttributeError: 'UniversalDatasetDetector' object has no attribute 'analyze_dataset'
```
**Impacto**: Bloquea testing completo
**Resoluci√≥n**: Implementar m√©todo faltante

**2. Error de Importaci√≥n LangGraph**
```
ImportError: cannot import name 'StateGraph' from 'langgraph'
```
**Impacto**: Previene inicializaci√≥n de orquestador real
**Resoluci√≥n**: Verificar versi√≥n y API de LangGraph

**3. Configuraci√≥n Pipenv**
```
Dependencias instaladas globalmente vs entorno pipenv
```
**Impacto**: Inconsistencia en entorno de desarrollo
**Resoluci√≥n**: Verificar instalaci√≥n en pipenv espec√≠fico

### üí° LECCIONES APRENDIDAS

1. **Arquitectura Modular**: La separaci√≥n clara entre detector, configurador y orquestador facilit√≥ la implementaci√≥n
2. **Testing Temprano**: Los tests comprensivos revelaron errores cr√≠ticos antes de integraci√≥n
3. **Manejo de Dependencias**: Importar con manejo de errores previene crashes en desarrollo
4. **Documentaci√≥n Incremental**: Registrar cambios facilita tracking y debugging

### üéØ PR√ìXIMOS PASOS INMEDIATOS

1. **Implementar m√©todo faltante** en `UniversalDatasetDetector`
2. **Resolver importaciones LangGraph** (verificar versi√≥n correcta)
3. **Ejecutar tests completos** hasta estado verde
4. ‚úÖ **Archivos temporales organizados** (movidos a directorio tests/)
5. **Iniciar FASE 3**: Simulaci√≥n avanzada y m√©tricas
6. **Documentar API** de los nuevos m√≥dulos

---

**Resumen**: FASE 1 y FASE 2 implementadas exitosamente con 90% de completitud. Sistema migrado a LangGraph con capacidad universal de procesamiento de datasets m√©dicos. Pendiente resolver 2 errores cr√≠ticos para finalizaci√≥n completa.

---
### üåü Principios Constitutivos del Sistema (Depurados en Sesi√≥n)

Estos principios definen el comportamiento fundamental y las capacidades del sistema, y deben ser respetados en todo el desarrollo:

*   **Flujo de Agentes Flexible y No Secuencial**:
    *   El sistema no impone un orden predefinido para la ejecuci√≥n de tareas. Despu√©s de cargar un dataset, el usuario puede invocar a cualquier agente especializado (`Analista`, `Generador`, `Validador`, `Simulador`, `Evaluador`) en cualquier momento y en cualquier orden.
    *   El control de la interacci√≥n siempre regresa al `Coordinador` despu√©s de que un agente especializado completa su tarea, permitiendo al usuario dar una nueva instrucci√≥n o continuar la conversaci√≥n.

*   **Coordinador como Asistente M√©dico de IA Conversacional**:
    *   El `Coordinador` es el punto de entrada principal para la interacci√≥n del usuario. Su rol es doble:
        1.  **Experto Conversacional**: Capaz de mantener di√°logos fluidos y naturales sobre una amplia gama de temas m√©dicos y de salud. Responde preguntas, proporciona explicaciones y ofrece orientaci√≥n, actuando como un experto en el dominio.
        2.  **Orquestador Inteligente**: Identifica la intenci√≥n del usuario (conversaci√≥n vs. comando de tarea). Si es un comando, prepara el contexto y delega la ejecuci√≥n al agente especializado correspondiente, sin realizar la tarea directamente.

*   **Prioridad de Datos para Agentes de Procesamiento**:
    *   Los agentes que procesan datos (especialmente `Validador`, `Simulador` y `Evaluador`) deben priorizar el uso de los datos sint√©ticos generados si estos existen en el estado del sistema.
    *   Si no hay datos sint√©ticos disponibles, estos agentes deben operar sobre los datos reales que hayan sido cargados previamente.

*   **Agente Generador**:
    *   El `Generador` siempre utilizar√° los datos reales cargados como base para la creaci√≥n de nuevos datasets sint√©ticos.

*   **Agente Analizador**:
    *   El `Analizador` operar√° sobre los datos disponibles, priorizando los datos sint√©ticos si existen, y si no, utilizando los datos reales cargados. Su funci√≥n es extraer patrones, caracter√≠sticas y realizar an√°lisis exploratorios.

*   **M√≥dulos de Soporte Especializados**:
    *   Cada agente especializado debe apoyarse en los m√≥dulos y funciones definidos en sus respectivas carpetas (`extraction`, `evaluation`, `generation`, `simulation`, `validation`) para llevar a cabo sus tareas. Esto asegura la modularidad y la separaci√≥n de responsabilidades.

*   **Elecci√≥n del Modelo de Generaci√≥n por el Usuario**:
    *   El usuario tiene la capacidad de especificar el m√©todo o modelo deseado para la generaci√≥n de datos sint√©ticos (ej., `CTGAN`, `TVAE`, `Gaussian Copula`). Esta elecci√≥n es expl√≠cita y no debe ser determinada autom√°ticamente por el sistema.


Visi√≥n General del Proyecto: Un Hospital Virtual Dirigido por Agentes


  El objetivo fundamental de este proyecto es crear un sistema inteligente y flexible capaz de:
   1. Analizar datasets m√©dicos reales (de COVID, diabetes, etc.).
   2. Comprender sus caracter√≠sticas cl√≠nicas y patrones.
   3. Generar datos sint√©ticos que sean realistas y m√©dicamente coherentes.
   4. Validar, simular y evaluar tanto los datos reales como los sint√©ticos.


  Para lograr esto, la arquitectura no es un script lineal, sino un sistema de agentes de IA que colaboran entre s√≠, orquestado por una biblioteca especializada llamada LangGraph. Piensa en
  ello como un equipo de especialistas m√©dicos en un hospital: hay un coordinador, un analista, un generador de pacientes, etc., y cada uno tiene un rol muy espec√≠fico.

  ---


  Fase 1: La Puesta en Marcha y los Componentes Clave


  Todo comienza cuando ejecutas la interfaz de usuario.


   1. `interfaces/chat_llm.py` (La Recepci√≥n del Hospital):
       * Funci√≥n: Este script utiliza Streamlit para crear la interfaz web con la que interact√∫as: el chat, la barra lateral, y el bot√≥n para subir archivos. Es la "cara" visible del sistema.
       * Conexi√≥n: Cuando se inicia, lo m√°s importante que hace es crear una instancia del MedicalAgentsOrchestrator, que es el cerebro de todo el sistema. Le pasa a este orquestador todos
         los agentes especializados que ha inicializado.


   2. `src/orchestration/langgraph_orchestrator.py` (El Director del Hospital):
       * Funci√≥n: Esta es la clase m√°s importante. Su trabajo es gestionar el flujo de trabajo (el "workflow") entre todos los agentes. Utiliza LangGraph para construir un grafo de estados,
         que es como un mapa que define qu√© agente debe actuar y cu√°ndo.
       * `__init__(self, agents)`: El constructor recibe a todos los agentes. Aqu√≠ se inicializan dos componentes cruciales de la FASE 2 de la refactorizaci√≥n:
           * UniversalDatasetDetector: El "m√©dico de triaje" que realiza un primer diagn√≥stico r√°pido del dataset.
           * DynamicPipelineConfig: El "planificador de protocolos" que decide qu√© an√°lisis y configuraciones usar seg√∫n el tipo de dataset.
       * `_create_workflow(self)`: Esta funci√≥n construye el mapa de LangGraph. Define los "nodos" (que son los agentes) y las "aristas" (que son las rutas o transiciones entre ellos).
         Establece que el flujo siempre comienza en el coordinator y que, despu√©s de que cualquier otro agente termine, el control vuelve al coordinator.

  ---


  Fase 2: El Flujo de una Tarea - "Analizar Datos"


  Aqu√≠ es donde ocurre la magia (y los errores). Sigamos el viaje de tu comando "analizar datos".


  Paso 1: Carga del Dataset
   * T√∫, el usuario, subes un archivo CSV desde la interfaz de Streamlit.
   * chat_llm.py lee este archivo y lo convierte en un DataFrame de Pandas.
   * Llama al m√©todo process_user_input del orquestador, pas√°ndole el DataFrame dentro de un diccionario de context.
   * El orquestador crea un AgentState (el estado global de la conversaci√≥n) y marca dataset_uploaded = True, guardando el DataFrame en el estado.


  Paso 2: El Comando "analizar datos"
   * Escribes "analizar datos" en el chat.
   * chat_llm.py vuelve a llamar a process_user_input del orquestador, esta vez con tu mensaje.


  Paso 3: El Coordinador Interpreta la Intenci√≥n
   * El workflow de LangGraph se inicia en el nodo _coordinator_node.
   * Este nodo invoca al `CoordinatorAgent` (src/agents/coordinator_agent.py).
   * El CoordinatorAgent es un agente LLM. Su system_prompt le instruye para que act√∫e como un asistente de IA que debe diferenciar entre una conversaci√≥n casual y un comando de tarea.
   * Al recibir "analizar datos", el agente lo reconoce como un comando y devuelve un resultado como: {'intention': 'comando', 'agent': 'analyzer'}. Este resultado se guarda en
     state.coordinator_response.


  Paso 4: El Enrutador Decide el Camino (Aqu√≠ estaba el primer error)
   * El control pasa del coordinador a la funci√≥n de enrutamiento: _route_from_coordinator.
   * Esta funci√≥n es el "controlador de tr√°fico" del hospital. Mira la intenci√≥n y el estado actual para decidir a qu√© especialista enviar al "paciente" (la tarea).
   * L√≥gica clave:
       1. Ve que la intenci√≥n es comando y el input es analizar.
       2. Comprueba si ya se ha hecho un an√°lisis universal (if not state.universal_analysis). Como es la primera vez, no se ha hecho.
       3. Decisi√≥n: Devuelve la cadena "universal_analyzer". LangGraph entiende esto y mueve el control al nodo _universal_analyzer_node.


  Paso 5: El An√°lisis Universal (El Triaje)
   * Se ejecuta el nodo _universal_analyzer_node.
   * Este nodo utiliza el UniversalDatasetDetector (src/adapters/universal_dataset_detector.py).
   * `UniversalDatasetDetector.analyze_dataset`: Esta es una funci√≥n clave. No usa un LLM. Utiliza expresiones regulares (regex) y listas de palabras clave (domain_keywords) para escanear los
     nombres de las columnas y una muestra de los datos. As√≠ es como detecta si el dataset es de COVID, diabetes, etc., y mapea las columnas (edad, sexo, diagn√≥sticos).
   * El resultado es un diccionario muy completo con el tipo de dataset, las columnas inferidas, patrones, etc.
   * El nodo _universal_analyzer_node guarda este resultado en state.universal_analysis y, muy importante, prepara un diccionario adaptado para el siguiente agente en
     state.context['analysis_result_for_analyzer'].
   * Nuestra correcci√≥n anterior: Al final, este nodo cambia el user_input a "continue_to_analyzer" para forzar el siguiente paso.


  Paso 6: La Vuelta al Enrutador y el An√°lisis Cl√≠nico (Aqu√≠ est√° el nuevo error)
   * El control vuelve al _coordinator_node y luego al _route_from_coordinator.
   * El enrutador ahora ve el user_input "continue_to_analyzer". Nuestra correcci√≥n anterior le dice que, en este caso, debe devolver "analyzer".
   * El control se mueve al nodo _analyzer_node.
   * `_analyzer_node`:
       1. Recupera el resultado del an√°lisis universal que preparamos en el paso anterior.
       2. Invoca al `ClinicalAnalyzerAgent` (src/agents/analyzer_agent.py).
       3. `ClinicalAnalyzerAgent.analyze_dataset`: Este agente S√ç usa un LLM. Recibe el contexto (ej: "esto es un dataset de COVID con estas columnas") y, bas√°ndose en su system_prompt (que
          tiene secciones especiales para COVID, diabetes, etc.), genera un informe de an√°lisis cl√≠nico detallado y en lenguaje natural.
       4. Aqu√≠ aparece la advertencia: ‚ö†Ô∏è Advertencia: No se detect√≥ un archivo filtrado en el an√°lisis. Esto es un log dentro del _analyzer_node que indica que una operaci√≥n opcional de
          filtrado no se realiz√≥ o no devolvi√≥ una ruta de archivo. No es la causa del bucle, sino un s√≠ntoma que ocurre dentro de √©l.
       5. El agente termina su informe y lo devuelve. El nodo _analyzer_node actualiza el estado marcando state.analysis_complete = True.


  Paso 7: El Bucle Infinito (La Causa del Error Actual)
   * El _analyzer_node termina. Seg√∫n el grafo (workflow.add_edge("analyzer", "coordinator")), el control vuelve al _coordinator_node.
   * EL PROBLEMA: El _analyzer_node, despu√©s de hacer su trabajo, no limpia ni modifica el `state.user_input`.
   * Por lo tanto, el _coordinator_node se encuentra de nuevo con que el user_input es "continue_to_analyzer".
   * El flujo se repite: el coordinador lo procesa, el enrutador lo env√≠a al analizador, el analizador trabaja, y devuelve el control sin limpiar la instrucci√≥n. Esto se repite hasta que
     LangGraph alcanza su l√≠mite de recursi√≥n.

  ---

  Diagn√≥stico y Soluci√≥n


   * Diagn√≥stico: El flujo de "an√°lisis" no se considera terminado despu√©s de que el ClinicalAnalyzerAgent hace su trabajo. El sistema se queda atascado en la instrucci√≥n "contin√∫a al
     analizador" porque esa instrucci√≥n nunca se borra del estado una vez completada.


   * Soluci√≥n Propuesta: Debemos modificar el _analyzer_node en src/orchestration/langgraph_orchestrator.py. Al final de este nodo, justo despu√©s de que el an√°lisis se complete con √©xito y se
     actualice el estado, debemos limpiar el user_input.

  El cambio ser√≠a a√±adir state.user_input = "" al final del _analyzer_node.

---

## üìã REGISTRO DE CAMBIOS IMPLEMENTADOS

### **Fecha**: Julio 11, 2025
### **Sesi√≥n**: Depuraci√≥n y Mejoras del Flujo de An√°lisis y Generaci√≥n

---

### üîß CAMBIOS PRINCIPALES REALIZADOS

#### **1. Correcci√≥n de Bucle de Recursi√≥n en An√°lisis**
- **Problema**: El `_universal_analyzer_node` no redirig√≠a correctamente el flujo, causando un bucle infinito al intentar re-analizar.
- **Soluci√≥n**: Modificado `src/orchestration/langgraph_orchestrator.py` (`_universal_analyzer_node`) para forzar el `user_input` a `"continue_to_analyzer"` y el `_route_from_coordinator` para manejar esta nueva ruta.
- **Archivos Modificados**: `src/orchestration/langgraph_orchestrator.py`

#### **2. Correcci√≥n de Visualizaci√≥n de Resultados de An√°lisis**
- **Problema**: El informe detallado del `ClinicalAnalyzerAgent` se generaba pero no se mostraba en la interfaz, apareciendo un mensaje gen√©rico.
- **Soluci√≥n**: Modificado `src/agents/analyzer_agent.py` (`analyze_dataset`) para asegurar que la respuesta del LLM se empaquete correctamente en la clave `message`.
- **Archivos Modificados**: `src/agents/analyzer_agent.py`

#### **3. Mejora en la Detecci√≥n de Tipos de Columna (UniversalDatasetDetector)**
- **Problema**: Columnas num√©ricas eran err√≥neamente clasificadas como fechas debido a un orden incorrecto de comprobaciones.
- **Soluci√≥n**: Invertido el orden de comprobaci√≥n en `src/adapters/universal_dataset_detector.py` (`_detect_type_by_content`) para priorizar la detecci√≥n num√©rica.
- **Archivos Modificados**: `src/adapters/universal_dataset_detector.py`

#### **4. Ajuste en la Generaci√≥n de Prompts para Diabetes**
- **Problema**: La plantilla especializada para diabetes en `ClinicalAnalyzerAgent` esperaba datos pre-calculados que no exist√≠an, causando fallos silenciosos.
- **Soluci√≥n**: Comentada la l√≥gica de la plantilla espec√≠fica de diabetes en `src/agents/analyzer_agent.py` para que se use la plantilla de an√°lisis general, m√°s robusta.
- **Archivos Modificados**: `src/agents/analyzer_agent.py`

#### **5. Correcci√≥n de `AttributeError` en Interfaz (Eliminar Archivo)**
- **Problema**: Al eliminar un archivo, la interfaz intentaba acceder a `st.session_state.file_uploaded` despu√©s de que esta fuera borrada, causando un error.
- **Soluci√≥n**: Modificado `interfaces/chat_llm.py` para usar `st.session_state.get('file_uploaded', False)` para un acceso seguro.
- **Archivos Modificados**: `interfaces/chat_llm.py`

#### **6. Mejora en la Extracci√≥n de Par√°metros de Generaci√≥n (CoordinatorAgent)**
- **Problema**: El `CoordinatorAgent` no extra√≠a `num_samples` y `model_type` de los comandos de generaci√≥n.
- **Soluci√≥n**: Actualizado el `system_prompt` y la l√≥gica de procesamiento en `src/agents/coordinator_agent.py` para instruir al LLM a extraer estos par√°metros y devolverlos en el JSON de respuesta.
- **Archivos Modificados**: `src/agents/coordinator_agent.py`

#### **7. Implementaci√≥n de Selecci√≥n de Columnas Condicional para Generaci√≥n**
- **Problema**: El generador usaba todas las columnas para COVID-19, y el modelo por defecto era `tvae`.
- **Soluci√≥n**: Modificado `src/orchestration/langgraph_orchestrator.py` (`_generator_node`) para:
    - Seleccionar solo 10 columnas espec√≠ficas para datasets COVID-19.
    - Usar todas las columnas para otros datasets.
    - Establecer `ctgan` como modelo por defecto.
- **Archivos Modificados**: `src/orchestration/langgraph_orchestrator.py`

#### **8. Clarificaci√≥n de Nomenclatura de Modelos (SDV vs. Gaussian Copula)**
- **Problema**: Se usaban `sdv` y `gaussian_copula` indistintamente, causando confusi√≥n.
- **Soluci√≥n**: Eliminada la referencia a `gaussian_copula` del `system_prompt` del `CoordinatorAgent` para estandarizar el uso de `sdv`.
- **Archivos Modificados**: `src/agents/coordinator_agent.py`

#### **9. Implementaci√≥n de Enrutamiento Determinista en Orquestador**
- **Problema**: El `CoordinatorAgent` a veces delegaba incorrectamente la tarea, causando que "generar" se enrutara a "analizar".
- **Soluci√≥n**: A√±adida una funci√≥n `_determine_agent_from_input` en `src/orchestration/langgraph_orchestrator.py` para identificar el agente de forma determinista. El `_route_from_coordinator` ahora usa esta funci√≥n.
- **Archivos Modificados**: `src/orchestration/langgraph_orchestrator.py`

#### **10. Correcci√≥n de Error Cr√≠tico en Construcci√≥n de Grafo (LangGraph)**
- **Problema**: El orquestador fallaba al inicializarse debido a un uso incorrecto de `add_edge` en lugar de `add_conditional_edges` para el nodo `universal_analyzer`. Esto forzaba el "modo simulado".
- **Soluci√≥n**: Corregido el `_create_workflow` en `src/orchestration/langgraph_orchestrator.py` para usar `add_conditional_edges` correctamente.
- **Archivos Modificados**: `src/orchestration/langgraph_orchestrator.py`

#### **12. Correcci√≥n Continua de Variables de Template en Prompts**
- **Problema**: Persistencia del error `'Input to ChatPromptTemplate is missing variables {'\n "dataset_type"'}` despu√©s de correcciones previas en `analyzer_agent.py` y `validator_agent.py`.
- **Progreso**: 
  - ‚úÖ Corregidos ejemplos JSON en `analyzer_agent.py` escapando llaves: `{` ‚Üí `{{` y `}` ‚Üí `}}`
  - ‚úÖ Simplificado prompt del `validator_agent.py` eliminando variables problem√°ticas como `{overall_score:.1%}`, `{clinical_coherence:.1%}`, etc.
  - ‚úÖ Todos los generadores (`ctgan_generator.py`, `tvae_generator.py`, `sdv_generator.py`) corregidos con signatura unificada: `generate(real_df, sample_size=None, is_covid_dataset=False)`
  - ‚úÖ Imports corregidos: `Metadata` ‚Üí `SingleTableMetadata` en todos los generadores
  - ‚úÖ Comentados imports problem√°ticos: `fix_json_generators` hasta que est√©n disponibles
- **Estado**: Error persiste, sugiriendo variable `dataset_type` con saltos de l√≠nea `'\n "dataset_type"'` en alg√∫n template din√°mico no identificado.
- **Archivos Modificados**: `src/agents/analyzer_agent.py`, `src/agents/validator_agent.py`, `src/generation/ctgan_generator.py`, `src/generation/tvae_generator.py`, `src/generation/sdv_generator.py`
- **Pendiente**: Identificar y corregir la fuente restante de la variable `dataset_type` problem√°tica en templates de LangChain.

---

## üìã REGISTRO DE CAMBIOS IMPLEMENTADOS

### **Fecha**: Julio 19, 2025
### **Sesi√≥n**: Limpieza de Archivos Temporales y de Prueba - Sistema Estabilizado

---

### üßπ LIMPIEZA COMPLETA REALIZADA

#### **1. Eliminaci√≥n de Archivos de Prueba en Ra√≠z**
- ‚úÖ Eliminado `test_orchestrator_analyzer.py` (archivo vac√≠o)
- ‚úÖ Eliminado `test_clip_button.py` (209 l√≠neas - prueba de interfaz obsoleta)
- ‚úÖ Eliminado `test_analyzer_fix.py` (archivo de prueba temporal)
- ‚úÖ Eliminado `diagnose_end_conversation.py` (archivo de diagn√≥stico vac√≠o)
- ‚úÖ Eliminado `medical_data_adapter.py.backup` (archivo de respaldo innecesario)
- **Resultado**: Directorio ra√≠z limpio de archivos de prueba temporales

#### **2. Eliminaci√≥n de Archivos Fix Obsoletos**
- ‚úÖ Eliminados todos los archivos `fix_*.py` en `utils/`:
  - `fix_tools.py`
  - `fix_streamlit_pytorch.py`
  - `fix_json_generators.py`
  - `fix_init_files.py`
  - `fix_chat_llm.py`
- ‚úÖ Eliminados todos los archivos `fix_*.py` en `src/utils/`:
  - `fix_tools.py`
  - `fix_streamlit_pytorch.py`
  - `fix_json_generators.py`
  - `fix_chat_llm.py`
- ‚úÖ Eliminado `fix_icon.py` del directorio ra√≠z
- **Resultado**: Sistema libre de archivos de correcci√≥n temporales

#### **3. Eliminaci√≥n Completa de Carpeta Temporal**
- ‚úÖ Eliminada carpeta `temp/` completa con todos sus archivos:
  - `boton_cargar.py`
  - `chat_llm_langgraph.py`
  - `chat_llm_unified.py`
  - `data_extractor.py`
  - `debug_diabetes_detection.py`
  - `debug_frontend_error.py`
  - `diagnose_end_conversation.py`
  - `medical_data_adapter.py.backup`
  - `pattern_extractor.py`
  - `test_analyzer_fix.py`
  - `test_enhanced_analyzer.py`
  - `test_flow_complete.py`
  - `test_orchestrator_analyzer.py`
- **Resultado**: Eliminados 13 archivos temporales de desarrollo

#### **4. Limpieza de Archivos de Debug y Carpetas Vac√≠as**
- ‚úÖ Eliminado `src/evaluation/evaluator_debug.py` (archivo de debug)
- ‚úÖ Eliminada carpeta `models/` (carpeta vac√≠a sin contenido)
- **Resultado**: Estructura de proyecto optimizada

#### **5. Archivos de Test Conservados (√ötiles para el Proyecto)**
Se mantuvieron los siguientes archivos de test por su utilidad:
- ‚úÖ `tests/test_dependencies.py` - Verificaci√≥n de dependencias del sistema
- ‚úÖ `tests/test_azure_basic.py` - Pruebas b√°sicas de conexi√≥n Azure
- ‚úÖ `tests/test_azure.py` - Pruebas de configuraci√≥n Azure
- ‚úÖ `tests/test_phase_1_2.py` - Tests de validaci√≥n FASE 1 y 2
- ‚úÖ `tests/test_integration_flow.py` - Tests de integraci√≥n del flujo
- ‚úÖ `tests/test_covid_pipeline.py` - Tests espec√≠ficos pipeline COVID
- ‚úÖ `tests/test_agent_flows.py` - Tests de flujos de agentes

### üìä RESUMEN DE LIMPIEZA

#### **Archivos Eliminados:**
```
üìÅ Archivos de prueba en ra√≠z: 4 archivos
üìÅ Archivos fix en utils/: 5 archivos  
üìÅ Archivos fix en src/utils/: 4 archivos
üìÅ Carpeta temp/ completa: 13 archivos
üìÅ Archivos de debug: 1 archivo
üìÅ Carpetas vac√≠as: 1 carpeta
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä TOTAL ELIMINADO: 28 archivos + 1 carpeta
```

#### **Archivos Conservados (Estructurales):**
```
‚úÖ tests/test_dependencies.py
‚úÖ tests/test_azure_basic.py
‚úÖ tests/test_azure.py
‚úÖ tests/test_phase_1_2.py
‚úÖ tests/test_integration_flow.py
‚úÖ tests/test_covid_pipeline.py
‚úÖ tests/test_agent_flows.py
‚úÖ utils/check_structure.py
‚úÖ utils/clean_json_files.py
‚úÖ src/utils/[archivos esenciales]
```

### üéØ BENEFICIOS DE LA LIMPIEZA

1. **Claridad del Proyecto**: Eliminaci√≥n de c√≥digo obsoleto y archivos temporales
2. **Reducci√≥n de Complejidad**: Menor cantidad de archivos para navegar y mantener
3. **Mejor Organizaci√≥n**: Solo archivos esenciales y funcionales permanecen
4. **Optimizaci√≥n de Espacio**: Reducci√≥n significativa del tama√±o del proyecto
5. **Mantenimiento Facilitado**: Estructura m√°s limpia para desarrollo futuro

### üöÄ ESTADO ACTUAL DEL PROYECTO

#### **Sistema Operativo y Funcional:**
- ‚úÖ An√°lisis de datos funcionando correctamente hasta generar informe detallado
- ‚úÖ Sistema de agentes LangGraph completamente operativo
- ‚úÖ Interfaz Streamlit optimizada y limpia
- ‚úÖ Detecci√≥n universal de datasets implementada
- ‚úÖ Configuraci√≥n din√°mica por tipo de dataset activa

#### **Pr√≥ximas Implementaciones (FASE 3):**
- [ ] Generaci√≥n sint√©tica completa con validaci√≥n
- [ ] Simulaci√≥n temporal de progresi√≥n cl√≠nica  
- [ ] Evaluaci√≥n de m√©tricas avanzadas
- [ ] Dashboard interactivo de resultados

---

**Resumen**: Proyecto completamente limpio y organizado. Sistema base funcionando correctamente hasta an√°lisis de datos. Listo para implementar FASE 3 (funcionalidades avanzadas) con una base de c√≥digo limpia y mantenible.

---

## üìã REQUISITOS PARA DATASETS M√âDICOS - GENERACI√ìN SINT√âTICA

### üéØ **Criterios de Validaci√≥n para Datasets M√©dicos**

El sistema `MedicalColumnSelector` implementa validaciones autom√°ticas para asegurar que solo datasets m√©dicos apropiados sean utilizados para generaci√≥n sint√©tica. A continuaci√≥n se detallan los requisitos espec√≠ficos:

---

### üîç **REQUISITOS T√âCNICOS OBLIGATORIOS**

#### **1. Tama√±o del Dataset**
- ‚úÖ **M√≠nimo:** 50 filas (registros de pacientes)
- üéØ **Recomendado:** 200+ filas para mejor calidad sint√©tica
- ‚ö†Ô∏è **Limitaci√≥n:** Datasets con <50 filas son rechazados autom√°ticamente

#### **2. Estructura de Columnas**
- ‚úÖ **M√≠nimo:** Al menos 2 columnas num√©ricas
- üéØ **Recomendado:** Mix de columnas num√©ricas y categ√≥ricas
- ‚ö†Ô∏è **Problema:** Datasets solo con texto son rechazados

---

### üè• **REQUISITOS M√âDICOS POR TIPO DE DATASET**

#### **üìä COVID-19 Datasets**
**Columnas OBLIGATORIAS:**
- `Patient ID` - Identificador √∫nico del paciente
- `Age` - Edad del paciente 
- `Diagnosis` - Diagn√≥stico principal relacionado con COVID-19

**Columnas RECOMENDADAS:**
- `Gender/Sex` - G√©nero del paciente
- `Vital Signs` - Signos vitales (temperatura, saturaci√≥n O2, presi√≥n arterial)

**Columnas OPCIONALES:**
- `Lab Results` - Resultados de PCR, ant√≠genos, an√°lisis de sangre
- `Medications` - Tratamientos aplicados
- `Comorbidities` - Condiciones preexistentes

#### **ü©∫ Diabetes Datasets**
**Columnas OBLIGATORIAS:**
- `Patient ID` - Identificador √∫nico del paciente
- `Age` - Edad del paciente
- `Diagnosis` - Tipo de diabetes (Tipo 1, Tipo 2, gestacional, etc.)

**Columnas RECOMENDADAS:**
- `Gender/Sex` - G√©nero del paciente
- `Lab Results` - Glucosa, HbA1c, valores de laboratorio

**Columnas OPCIONALES:**
- `Medications` - Insulina, metformina, otros medicamentos
- `Vital Signs` - Presi√≥n arterial, IMC
- `Complications` - Complicaciones diab√©ticas

#### **üè• General Medical Datasets**
**Columnas OBLIGATORIAS:**
- `Patient ID` - Identificador √∫nico del paciente
- `Age` - Edad del paciente
- `Diagnosis` - Diagn√≥stico principal o condici√≥n m√©dica

**Columnas RECOMENDADAS:**
- `Gender/Sex` - G√©nero del paciente

---

### üîß **DETECCI√ìN AUTOM√ÅTICA DE COLUMNAS**

El sistema utiliza algoritmos inteligentes para detectar autom√°ticamente los tipos de columnas:

#### **Identificadores de Paciente:**
```
Patrones detectados: 'patient_id', 'id_patient', 'patient', 'identifier', 'subject_id'
Ejemplo: "PAT_001", "12345", "SUBJ_ABC"
```

#### **Edad:**
```
Patrones detectados: 'age', 'edad', 'years', 'a√±os', 'birth_age'
Ejemplo: 25, 67, 45
```

#### **G√©nero:**
```
Patrones detectados: 'sex', 'gender', 'sexo', 'g√©nero', 'male_female'
Ejemplo: "M/F", "Male/Female", "Masculino/Femenino"
```

#### **Diagn√≥sticos:**
```
Patrones detectados: 'diagnosis', 'diagnostic', 'condition', 'disease', 'icd'
Ejemplo: "COVID-19", "Diabetes Type 2", "J44.0"
```

#### **Medicamentos:**
```
Patrones detectados: 'medication', 'drug', 'medicine', 'treatment', 'therapy'
Ejemplo: "Metformin", "Insulin", "Paracetamol"
```

#### **Resultados de Laboratorio:**
```
Patrones detectados: 'lab', 'laboratory', 'test', 'result', 'blood', 'glucose'
Ejemplo: 120, 7.5, "Positive", "Normal"
```

---

### ‚ö†Ô∏è **ERRORES COMUNES Y SOLUCIONES**

#### **Error: "Dataset muy peque√±o"**
```
Problema: Menos de 50 filas
Soluci√≥n: Obtener m√°s registros de pacientes o combinar datasets similares
```

#### **Error: "Falta columna obligatoria: Identificador √∫nico del paciente"**
```
Problema: No se detect√≥ columna de ID de paciente
Soluci√≥n: Renombrar columna existente o crear IDs √∫nicos (ej: 'patient_id')
```

#### **Error: "Falta columna obligatoria: Edad del paciente"**
```
Problema: No se detect√≥ columna de edad
Soluci√≥n: Incluir columna 'age' con valores num√©ricos de edad
```

#### **Error: "Falta columna obligatoria: Diagn√≥stico principal"**
```
Problema: No se detect√≥ columna de diagn√≥stico m√©dico
Soluci√≥n: Incluir columna con diagn√≥sticos (ej: 'diagnosis', 'condition')
```

#### **Error: "Dataset debe tener al menos 2 columnas num√©ricas"**
```
Problema: Todas las columnas son categ√≥ricas/texto
Soluci√≥n: Incluir datos num√©ricos como edad, valores de laboratorio, signos vitales
```

---

### üìà **OPTIMIZACI√ìN DE CALIDAD**

#### **Score de Calidad (0.0 - 1.0):**
- **0.8 - 1.0:** Excelente - Dataset ideal para generaci√≥n sint√©tica
- **0.6 - 0.8:** Bueno - Aceptable con peque√±as mejoras
- **0.4 - 0.6:** Regular - Requiere mejoras significativas  
- **0.0 - 0.4:** Pobre - No recomendado para generaci√≥n

#### **Factores que Mejoran el Score:**
1. **Cumplimiento de requisitos obligatorios** (peso: 1.0)
2. **Cumplimiento de requisitos recomendados** (peso: 0.5)
3. **Diversidad de tipos de columnas** (peso: 1.0)
4. **Alta confianza en detecci√≥n autom√°tica** (mejora score individual)

---

### üöÄ **RECOMENDACIONES PARA PREPARAR DATASETS**

#### **1. Nombres de Columnas Claros:**
```
‚úÖ Bueno: 'patient_id', 'age', 'gender', 'diagnosis'
‚ùå Evitar: 'col1', 'data', 'value', nombres ambiguos
```

#### **2. Consistencia en Datos:**
```
‚úÖ Bueno: Valores consistentes ("M"/"F" para g√©nero)
‚ùå Evitar: Mezclar formatos ("Male"/"F"/"Masculino")
```

#### **3. Gesti√≥n de Valores Faltantes:**
```
‚úÖ Bueno: <10% valores nulos por columna importante
‚ö†Ô∏è Cuidado: >30% valores nulos afecta calidad sint√©tica
```

#### **4. Tipos de Datos Apropiados:**
```
‚úÖ Edad: Num√©rico entero (25, 67, 45)
‚úÖ G√©nero: Categ√≥rico ("M", "F")
‚úÖ Diagn√≥stico: Texto estructurado ("COVID-19", "Diabetes Type 2")
‚úÖ Labs: Num√©rico decimal (120.5, 7.8)
```

---

### üìã **CHECKLIST PRE-CARGA**

Antes de cargar tu dataset, verifica:

- [ ] **Tama√±o:** ¬øTiene al menos 50 filas?
- [ ] **ID Paciente:** ¬øHay columna con identificadores √∫nicos?
- [ ] **Edad:** ¬øHay columna con edades num√©ricas?
- [ ] **Diagn√≥stico:** ¬øHay columna con condiciones m√©dicas?
- [ ] **Columnas Num√©ricas:** ¬øAl menos 2 columnas con valores num√©ricos?
- [ ] **Nombres Claros:** ¬øLos nombres de columnas son descriptivos?
- [ ] **Datos Limpios:** ¬øValores consistentes y m√≠nimos nulos?

### üí° **EJEMPLO DE DATASET V√ÅLIDO**

```csv
patient_id,age,gender,diagnosis,glucose_level,blood_pressure,medication
PAT_001,45,M,Diabetes Type 2,180,140/90,Metformin
PAT_002,67,F,COVID-19,95,120/80,Paracetamol
PAT_003,23,F,Hypertension,88,150/95,Lisinopril
...
```

**‚úÖ Este dataset es v√°lido porque:**
- Tiene ID √∫nico de paciente
- Incluye edad num√©rica  
- Tiene diagn√≥sticos m√©dicos
- Contiene m√∫ltiples columnas num√©ricas
- Nombres de columnas claros



# üîß SOLUCION: Problema "Modelo N/A" en Datos Sint√©ticos

## üìã PROBLEMA IDENTIFICADO

El usuario report√≥ que en la interfaz aparec√≠a informaci√≥n confusa:

```
Datos Sint√©ticos Generados
Registros: 100
Columnas: 10  
Modelo: N/A

Detalles de generaci√≥n:
Modelo: N/A
M√©todo: N/A
Columnas utilizadas: N/A
```

## üîç CAUSA RA√çZ

1. **Informaci√≥n incompleta**: Los agentes mock y reales no siempre devolv√≠an `generation_info` completo
2. **Manejo inconsistente**: Hab√≠a dos lugares diferentes donde se procesaban los datos sint√©ticos, con l√≥gica diferente
3. **Falta de fallbacks**: No hab√≠a valores por defecto cuando `generation_info` estaba vac√≠o o incompleto

## ‚úÖ SOLUCI√ìN IMPLEMENTADA

### 1. Funci√≥n Centralizada
```python
def handle_synthetic_data_response(response, context=None):
    """Maneja la respuesta de generaci√≥n sint√©tica de forma centralizada"""
```

**Caracter√≠sticas:**
- ‚úÖ Manejo centralizado de datos sint√©ticos  
- ‚úÖ Creaci√≥n autom√°tica de `generation_info` cuando falta
- ‚úÖ Validaci√≥n y correcci√≥n de datos inconsistentes
- ‚úÖ Valores por defecto inteligentes

### 2. Mejoras en Display

**Antes:**
```
Modelo: N/A
M√©todo: N/A  
Columnas utilizadas: N/A
```

**Despu√©s:**
```
Modelo: CTGAN / TVAE / SDV (o "GENERADO" si no se conoce)
M√©todo: "M√©todo est√°ndar" en lugar de N/A
Columnas utilizadas: N√∫mero real de columnas del DataFrame
```

### 3. Fallbacks Inteligentes

| Campo | Valor por Defecto | L√≥gica |
|-------|------------------|--------|
| `model_type` | "ctgan" | Del contexto o par√°metros, fallback a CTGAN |
| `num_samples` | `len(synthetic_df)` | N√∫mero real de filas generadas |
| `columns_used` | `len(synthetic_df.columns)` | N√∫mero real de columnas |
| `selection_method` | "Autom√°tico" / "Columnas seleccionadas" | Basado en contexto |
| `timestamp` | Timestamp actual | Para archivos √∫nicos |

## üéØ RESULTADO PARA EL USUARIO

### Caso 1: Con informaci√≥n completa
```
Datos Sint√©ticos Generados
Registros: 100
Columnas: 5
Modelo: TVAE

üî¨ Detalles de generaci√≥n:
Modelo utilizado: TVAE
Registros generados: 100
M√©todo de selecci√≥n: Columnas seleccionadas  
Columnas utilizadas: 5
```

### Caso 2: Sin informaci√≥n (fallback)
```
Datos Sint√©ticos Generados
Registros: 100
Columnas: 10
Modelo: GENERADO

üìä Informaci√≥n de los datos:
Datos sint√©ticos generados exitosamente
Columnas: 10
M√©todo: Generaci√≥n est√°ndar
```

## üî¨ VALIDACI√ìN

- ‚úÖ Funci√≥n centralizada manejando todos los casos edge
- ‚úÖ Display consistente en ambas secciones del sidebar
- ‚úÖ Eliminaci√≥n de mensajes confusos "N/A" 
- ‚úÖ Tests creados para validar el comportamiento

## üì± EXPERIENCIA DE USUARIO

**Antes**: Confuso y t√©cnico ("N/A" en todas partes)
**Despu√©s**: Claro y profesional (informaci√≥n real o fallbacks √∫tiles)

El usuario ahora siempre ver√° informaci√≥n √∫til y comprensible, incluso cuando los datos t√©cnicos internos no est√©n disponibles.
